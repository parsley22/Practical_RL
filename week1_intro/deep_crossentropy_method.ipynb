{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../xvfb: line 2: $'\\r': command not found\n",
      "../xvfb: line 4: $'\\r': command not found\n",
      "../xvfb: line 8: $'\\r': command not found\n",
      "../xvfb: line 9: syntax error near unexpected token `$'in\\r''\n",
      "../xvfb: line 9: `case \"$1\" in\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARhklEQVR4nO3df4xdZ33n8fenSQhsQU1CJpHrH3VavFrS1eLQ2eAq/SMNtA3R7hokWCW7KhaKNKwUJJDQbpNW2oLUSK3UkgptN8JVUkxFCdkCihulC1kTVPEHCTYYY2PSGDBkait2liSA0Gbr8O0f9xm4da491zNzM37mvl/S1T3ne55z5/soNx8fP3Oub6oKSVI/fma1G5AknRuDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMxML7iQ3Jnk8yZEkt0/q50jStMkk7uNOcgHw98BvAPPAl4BbqurrK/7DJGnKTOqK+1rgSFV9q6r+P3AfsH1CP0uSpsqFE3rd9cCTQ/vzwBvONPjyyy+vzZs3T6gVSerP0aNHefrppzPq2KSCe9QP+2drMknmgDmATZs2sXfv3gm1Ikn9mZ2dPeOxSS2VzAMbh/Y3AMeGB1TVzqqararZmZmZCbUhSWvPpIL7S8CWJFcleRlwM7B7Qj9LkqbKRJZKqupUkncDnwEuAO6tqkOT+FmSNG0mtcZNVT0EPDSp15ekaeUnJyWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdWZZX12W5CjwA+AF4FRVzSa5DPgEsBk4CvzHqnpmeW1KkhasxBX3r1fV1qqabfu3A3uqaguwp+1LklbIJJZKtgO72vYu4C0T+BmSNLWWG9wFfDbJviRzrXZlVR0HaM9XLPNnSJKGLGuNG7iuqo4luQJ4OMk3xj2xBf0cwKZNm5bZhiRNj2VdcVfVsfZ8Avg0cC3wVJJ1AO35xBnO3VlVs1U1OzMzs5w2JGmqLDm4k/xsklctbAO/CRwEdgM72rAdwAPLbVKS9FPLWSq5Evh0koXX+auq+t9JvgTcn+RW4LvA25ffpiRpwZKDu6q+BbxuRP3/Am9cTlOSpDPzk5OS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZxYN7iT3JjmR5OBQ7bIkDyd5oj1f2upJ8qEkR5IcSPL6STYvSdNonCvujwA3nla7HdhTVVuAPW0f4M3AlvaYA+5emTYlSQsWDe6q+jvge6eVtwO72vYu4C1D9Y/WwBeBS5KsW6lmJUlLX+O+sqqOA7TnK1p9PfDk0Lj5VnuRJHNJ9ibZe/LkySW2IUnTZ6V/OZkRtRo1sKp2VtVsVc3OzMyscBuStHYtNbifWlgCac8nWn0e2Dg0bgNwbOntSZJOt9Tg3g3saNs7gAeG6u9od5dsA55bWFKRJK2MCxcbkOTjwPXA5Unmgd8H/hC4P8mtwHeBt7fhDwE3AUeAHwHvnEDPkjTVFg3uqrrlDIfeOGJsAbcttylJ0pn5yUlJ6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ1ZNLiT3JvkRJKDQ7X3J/mHJPvb46ahY3ckOZLk8SS/NanGJWlajXPF/RHgxhH1u6pqa3s8BJDkauBm4JfbOf8zyQUr1awkaYzgrqq/A7435uttB+6rquer6tsMvu392mX0J0k6zXLWuN+d5EBbSrm01dYDTw6NmW+1F0kyl2Rvkr0nT55cRhuSNF2WGtx3A78EbAWOA3/S6hkxtka9QFXtrKrZqpqdmZlZYhuSNH2WFNxV9VRVvVBVPwb+nJ8uh8wDG4eGbgCOLa9FSdKwJQV3knVDu28FFu442Q3cnOTiJFcBW4DHlteiJGnYhYsNSPJx4Hrg8iTzwO8D1yfZymAZ5CjwLoCqOpTkfuDrwCngtqp6YTKtS9J0WjS4q+qWEeV7zjL+TuDO5TQlSTozPzkpSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOrPo7YDSWrZv57teVPuVuQ+vQifS+LzilqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOrNocCfZmOSRJIeTHErynla/LMnDSZ5oz5e2epJ8KMmRJAeSvH7Sk5CkaTLOFfcp4H1V9VpgG3BbkquB24E9VbUF2NP2Ad7M4NvdtwBzwN0r3rUkTbFFg7uqjlfVl9v2D4DDwHpgO7CrDdsFvKVtbwc+WgNfBC5Jsm7FO5ekKXVOa9xJNgPXAI8CV1bVcRiEO3BFG7YeeHLotPlWO/215pLsTbL35MmT5965JE2psYM7ySuBTwLvrarvn23oiFq9qFC1s6pmq2p2ZmZm3DYkaeqNFdxJLmIQ2h+rqk+18lMLSyDt+USrzwMbh07fABxbmXYlSePcVRLgHuBwVX1w6NBuYEfb3gE8MFR/R7u7ZBvw3MKSitSDUd+KI51PxvnqsuuA3wa+lmR/q/0u8IfA/UluBb4LvL0dewi4CTgC/Ah454p2LElTbtHgrqovMHrdGuCNI8YXcNsy+5IknYGfnJSkzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1Jlxvix4Y5JHkhxOcijJe1r9/Un+Icn+9rhp6Jw7khxJ8niS35rkBCRp2ozzZcGngPdV1ZeTvArYl+Thduyuqvrj4cFJrgZuBn4Z+Hng/yT5l1X1wko2LknTatEr7qo6XlVfbts/AA4D689yynbgvqp6vqq+zeDb3q9diWYlSee4xp1kM3AN8GgrvTvJgST3Jrm01dYDTw6dNs/Zg16SdA7GDu4krwQ+Cby3qr4P3A38ErAVOA78ycLQEafXiNebS7I3yd6TJ0+ec+OSNK3GCu4kFzEI7Y9V1acAquqpqnqhqn4M/Dk/XQ6ZBzYOnb4BOHb6a1bVzqqararZmZmZ5cxBWrJfmfvwarcgnbNx7ioJcA9wuKo+OFRfNzTsrcDBtr0buDnJxUmuArYAj61cy5I03ca5q+Q64LeBryXZ32q/C9ySZCuDZZCjwLsAqupQkvuBrzO4I+U27yiRpJWzaHBX1RcYvW790FnOuRO4cxl9SZLOwE9OSlJnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbg1pqUZOzHJM6XJsnglqTOjPNFCtKa9zfH5n6y/e9/fucqdiItzituTb3h0B61L51vDG5J6sw4Xxb88iSPJflqkkNJPtDqVyV5NMkTST6R5GWtfnHbP9KOb57sFCRpuoxzxf08cENVvQ7YCtyYZBvwR8BdVbUFeAa4tY2/FXimql4D3NXGSeet09e0XePW+W6cLwsu4Idt96L2KOAG4D+1+i7g/cDdwPa2DfDXwP9IkvY60nln9l07gZ+G9QdWrxVpLGPdVZLkAmAf8Brgz4BvAs9W1ak2ZB5Y37bXA08CVNWpJM8BrwaePtPr79u3z/th1S3fu3qpjRXcVfUCsDXJJcCngdeOGtaeR72LX3S1nWQOmAPYtGkT3/nOd8ZqWBrHSxmm/mVSkzA7O3vGY+d0V0lVPQt8HtgGXJJkIfg3AMfa9jywEaAd/zngeyNea2dVzVbV7MzMzLm0IUlTbZy7SmbalTZJXgG8CTgMPAK8rQ3bATzQtne3fdrxz7m+LUkrZ5ylknXArrbO/TPA/VX1YJKvA/cl+QPgK8A9bfw9wF8mOcLgSvvmCfQtSVNrnLtKDgDXjKh/C7h2RP3/AW9fke4kSS/iJyclqTMGtyR1xuCWpM74z7pqTfJGJq1lXnFLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM6M82XBL0/yWJKvJjmU5AOt/pEk306yvz22tnqSfCjJkSQHkrx+0pOQpGkyzr/H/TxwQ1X9MMlFwBeS/G079l+r6q9PG/9mYEt7vAG4uz1LklbAolfcNfDDtntRe5ztX6nfDny0nfdF4JIk65bfqiQJxlzjTnJBkv3ACeDhqnq0HbqzLYfcleTiVlsPPDl0+nyrSZJWwFjBXVUvVNVWYANwbZJ/DdwB/Cvg3wKXAb/ThmfUS5xeSDKXZG+SvSdPnlxS85I0jc7prpKqehb4PHBjVR1vyyHPA38BXNuGzQMbh07bABwb8Vo7q2q2qmZnZmaW1LwkTaNx7iqZSXJJ234F8CbgGwvr1kkCvAU42E7ZDbyj3V2yDXiuqo5PpHtJmkLj3FWyDtiV5AIGQX9/VT2Y5HNJZhgsjewH/ksb/xBwE3AE+BHwzpVvW5Km16LBXVUHgGtG1G84w/gCblt+a5KkUfzkpCR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6kyqarV7IMkPgMdXu48JuRx4erWbmIC1Oi9Yu3NzXn35haqaGXXgwpe6kzN4vKpmV7uJSUiydy3Oba3OC9bu3JzX2uFSiSR1xuCWpM6cL8G9c7UbmKC1Ore1Oi9Yu3NzXmvEefHLSUnS+M6XK25J0phWPbiT3Jjk8SRHkty+2v2cqyT3JjmR5OBQ7bIkDyd5oj1f2upJ8qE21wNJXr96nZ9dko1JHklyOMmhJO9p9a7nluTlSR5L8tU2rw+0+lVJHm3z+kSSl7X6xW3/SDu+eTX7X0ySC5J8JcmDbX+tzOtokq8l2Z9kb6t1/V5cjlUN7iQXAH8GvBm4GrglydWr2dMSfAS48bTa7cCeqtoC7Gn7MJjnlvaYA+5+iXpcilPA+6rqtcA24Lb236b3uT0P3FBVrwO2Ajcm2Qb8EXBXm9czwK1t/K3AM1X1GuCuNu589h7g8ND+WpkXwK9X1dahW/96fy8uXVWt2gP4VeAzQ/t3AHesZk9LnMdm4ODQ/uPAura9jsF96gAfBm4ZNe58fwAPAL+xluYG/Avgy8AbGHyA48JW/8n7EvgM8Ktt+8I2Lqvd+xnms4FBgN0APAhkLcyr9XgUuPy02pp5L57rY7WXStYDTw7tz7da766squMA7fmKVu9yvu2v0dcAj7IG5taWE/YDJ4CHgW8Cz1bVqTZkuPefzKsdfw549Uvb8dj+FPhvwI/b/qtZG/MCKOCzSfYlmWu17t+LS7Xan5zMiNpavs2lu/kmeSXwSeC9VfX9ZNQUBkNH1M7LuVXVC8DWJJcAnwZeO2pYe+5iXkn+HXCiqvYluX6hPGJoV/Macl1VHUtyBfBwkm+cZWxvcztnq33FPQ9sHNrfABxbpV5W0lNJ1gG05xOt3tV8k1zEILQ/VlWfauU1MTeAqnoW+DyDNfxLkixcyAz3/pN5teM/B3zvpe10LNcB/yHJUeA+Bsslf0r/8wKgqo615xMM/rC9ljX0XjxXqx3cXwK2tN98vwy4Gdi9yj2thN3Ajra9g8H68EL9He233tuA5xb+qne+yeDS+h7gcFV9cOhQ13NLMtOutEnyCuBNDH6Z9wjwtjbs9HktzPdtwOeqLZyeT6rqjqraUFWbGfx/9Lmq+s90Pi+AJD+b5FUL28BvAgfp/L24LKu9yA7cBPw9g3XG31vtfpbQ/8eB48A/MviT/lYGa4V7gCfa82VtbBjcRfNN4GvA7Gr3f5Z5/RqDv14eAPa3x029zw34N8BX2rwOAv+91X8ReAw4Avwv4OJWf3nbP9KO/+Jqz2GMOV4PPLhW5tXm8NX2OLSQE72/F5fz8JOTktSZ1V4qkSSdI4NbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTO/BPsS+9U796rowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba(env.reset().reshape(1,-1)).flatten()\n",
    "        \n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(np.arange(env.action_space.n), p = probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[ 0.02020483 -0.02316134  0.02786156  0.02154525]\n",
      " [-0.04072139  0.15995638  0.02422115 -0.3311803 ]\n",
      " [-0.01920173  0.19534055 -0.03774259 -0.3199392 ]\n",
      " [-0.00559878  0.23686434  0.01062648 -0.26895711]\n",
      " [-0.00455412 -0.1856852  -0.05013272  0.22915864]]\n",
      "actions: [1, 1, 1, 0, 1]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    \n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    \n",
    "    for ix,r in enumerate(rewards_batch):\n",
    "        if r >= reward_threshold:\n",
    "            elite_states.append(states_batch[ix])\n",
    "            elite_actions.append(actions_batch[ix])\n",
    "    \n",
    "    elite_states = [i for sublist in elite_states for i in sublist]\n",
    "    elite_actions = [i for sublist in elite_actions for i in sublist]\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 1000.000, threshold=1000.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-289e2268a17a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# generate new sessions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msessions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-289e2268a17a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# generate new sessions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msessions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-2a7d50d42c25>\u001b[0m in \u001b[0;36mgenerate_session\u001b[1;34m(env, agent, t_max)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"make sure probabilities are a vector (hint: np.reshape)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(env, agent) for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    agent.partial_fit(elite_states, elite_actions)\n",
    "    #<YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-3b7cca83513d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CartPole-v0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"videos\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0menv_monitor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msessions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_monitor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-3b7cca83513d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CartPole-v0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"videos\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0menv_monitor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msessions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_monitor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-2a7d50d42c25>\u001b[0m in \u001b[0;36mgenerate_session\u001b[1;34m(env, agent, t_max)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         )\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_ansi_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_image_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36m_encode_image_frame\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_encode_image_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes_per_sec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_frames_per_sec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoder_version'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, output_path, frame_shape, frames_per_sec, output_frames_per_sec)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ffmpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`."
     ]
    }
   ],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-7edc6c468764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;33m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"{}\"\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"video/mp4\"\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \"\"\".format(video_names[-1]))  # You can also try other indices\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: MountainCar\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "_if you have any trouble with CartPole-v0 and feel stuck, take a look at the forums_\n",
    "\n",
    "Your assignment is to obtain average reward of __at least -150__ on `MountainCar-v0`.\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "  \n",
    "* Bonus quest: Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith gym.make('MountainCar-v0').env as env:\\n    visualize_mountain_car(env, agent_mountain_car)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    # Compute policy for all possible x and v (with discretization)\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    \n",
    "    grid = np.dstack(np.meshgrid(xs, vs[::-1])).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3).transpose(1, 0, 2)\n",
    "\n",
    "    # # The above code is equivalent to the following:\n",
    "    # probs = np.empty((len(vs), len(xs), 3))\n",
    "    # for i, v in enumerate(vs[::-1]):\n",
    "    #     for j, x in enumerate(xs):\n",
    "    #         probs[i, j, :] = agent.predict_proba([[x, v]])[0]\n",
    "\n",
    "    # Draw policy\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.imshow(probs, extent=(env.min_position, env.max_position, -env.max_speed, env.max_speed), aspect='auto')\n",
    "    ax.set_title('Learned policy: red=left, green=nothing, blue=right')\n",
    "    ax.set_xlabel('position (x)')\n",
    "    ax.set_ylabel('velocity (v)')\n",
    "    \n",
    "    # Sample a trajectory and draw it\n",
    "    states, actions, _ = generate_session(env, agent)\n",
    "    states = np.array(states)\n",
    "    ax.plot(states[:, 0], states[:, 1], color='white')\n",
    "    \n",
    "    # Draw every 3rd action from the trajectory\n",
    "    for (x, v), a in zip(states[::3], actions[::3]):\n",
    "        if a == 0:\n",
    "            plt.arrow(x, v, -0.1, 0, color='white', head_length=0.02)\n",
    "        elif a == 2:\n",
    "            plt.arrow(x, v, 0.1, 0, color='white', head_length=0.02)\n",
    "\n",
    "\"\"\"\n",
    "with gym.make('MountainCar-v0').env as env:\n",
    "    visualize_mountain_car(env, agent_mountain_car)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.56418032,  0.00131339]),\n",
       "  array([-0.56356332,  0.000617  ]),\n",
       "  array([-5.63647312e-01, -8.39878048e-05]),\n",
       "  array([-0.56443166, -0.00078435]),\n",
       "  array([-0.56591052, -0.00147886]),\n",
       "  array([-0.5670729 , -0.00116238]),\n",
       "  array([-0.56891015, -0.00183725]),\n",
       "  array([-0.5714086 , -0.00249846]),\n",
       "  array([-0.57454971, -0.00314111]),\n",
       "  array([-0.57831018, -0.00376046]),\n",
       "  array([-0.58266215, -0.00435197]),\n",
       "  array([-0.58757345, -0.00491131]),\n",
       "  array([-0.59200789, -0.00443444]),\n",
       "  array([-0.59593286, -0.00392496]),\n",
       "  array([-0.59931956, -0.00338671]),\n",
       "  array([-0.60114323, -0.00182367]),\n",
       "  array([-0.60339055, -0.00224732]),\n",
       "  array([-0.60404514, -0.00065458]),\n",
       "  array([-0.60510221, -0.00105707]),\n",
       "  array([-6.05554077e-01, -4.51869550e-04]),\n",
       "  array([-0.60639746, -0.00084338]),\n",
       "  array([-6.06626211e-01, -2.28754983e-04]),\n",
       "  array([-6.06238679e-01,  3.87531742e-04]),\n",
       "  array([-0.60523768,  0.001001  ]),\n",
       "  array([-0.60363049,  0.00160719]),\n",
       "  array([-0.60242881,  0.00120168]),\n",
       "  array([-0.6016414 ,  0.00078741]),\n",
       "  array([-6.01274009e-01,  3.67394207e-04]),\n",
       "  array([-0.60032931,  0.0009447 ]),\n",
       "  array([-0.5978142 ,  0.00251511]),\n",
       "  array([-0.59574706,  0.00206714]),\n",
       "  array([-0.59414302,  0.00160404]),\n",
       "  array([-0.59201385,  0.00212918]),\n",
       "  array([-0.58937515,  0.0026387 ]),\n",
       "  array([-0.58724633,  0.00212882]),\n",
       "  array([-0.58364304,  0.00360328]),\n",
       "  array([-0.57859186,  0.00505118]),\n",
       "  array([-0.57313009,  0.00546176]),\n",
       "  array([-0.56729821,  0.00583188]),\n",
       "  array([-0.56213952,  0.00515869]),\n",
       "  array([-0.55669242,  0.0054471 ]),\n",
       "  array([-0.55199752,  0.0046949 ]),\n",
       "  array([-0.54708989,  0.00490763]),\n",
       "  array([-0.54300622,  0.00408367]),\n",
       "  array([-0.53977708,  0.00322914]),\n",
       "  array([-0.53542664,  0.00435043]),\n",
       "  array([-0.53198752,  0.00343912]),\n",
       "  array([-0.52848549,  0.00350203]),\n",
       "  array([-0.52594681,  0.00253868]),\n",
       "  array([-0.52439052,  0.00155629]),\n",
       "  array([-0.52382829,  0.00056223]),\n",
       "  array([-0.52326434,  0.00056395]),\n",
       "  array([-0.5217029 ,  0.00156144]),\n",
       "  array([-0.52015568,  0.00154722]),\n",
       "  array([-0.51963428,  0.0005214 ]),\n",
       "  array([-5.19142612e-01,  4.91666806e-04]),\n",
       "  array([-0.51968437, -0.00054175]),\n",
       "  array([-0.52025548, -0.00057111]),\n",
       "  array([-0.52085166, -0.00059619]),\n",
       "  array([-0.52146845, -0.00061679]),\n",
       "  array([-0.52310122, -0.00163277]),\n",
       "  array([-0.52373771, -0.0006365 ]),\n",
       "  array([-0.52537317, -0.00163546]),\n",
       "  array([-0.52799532, -0.00262215]),\n",
       "  array([-0.53058449, -0.00258917]),\n",
       "  array([-0.53412127, -0.00353679]),\n",
       "  array([-0.53657915, -0.00245788]),\n",
       "  array([-0.53993971, -0.00336055]),\n",
       "  array([-0.54317775, -0.00323804]),\n",
       "  array([-0.54626904, -0.00309129]),\n",
       "  array([-0.55019042, -0.00392139]),\n",
       "  array([-0.55291259, -0.00272216]),\n",
       "  array([-0.55641518, -0.00350259]),\n",
       "  array([-0.55867205, -0.00225687]),\n",
       "  array([-0.56166635, -0.0029943 ]),\n",
       "  array([-0.56437577, -0.00270942]),\n",
       "  array([-0.56778012, -0.00340435]),\n",
       "  array([-0.57185408, -0.00407396]),\n",
       "  array([-0.57656739, -0.00471331]),\n",
       "  array([-0.58088511, -0.00431771]),\n",
       "  array([-0.58477528, -0.00389018]),\n",
       "  array([-0.58920921, -0.00443393]),\n",
       "  array([-0.59415423, -0.00494502]),\n",
       "  array([-0.59857402, -0.0044198 ]),\n",
       "  array([-0.60143623, -0.00286221]),\n",
       "  array([-0.60271996, -0.00128372]),\n",
       "  array([-0.60341582, -0.00069587]),\n",
       "  array([-0.60451877, -0.00110294]),\n",
       "  array([-6.04020757e-01,  4.98011791e-04]),\n",
       "  array([-6.03925415e-01,  9.53420265e-05]),\n",
       "  array([-6.04233437e-01, -3.08022116e-04]),\n",
       "  array([-0.60294258,  0.00129086]),\n",
       "  array([-0.60106225,  0.00188033]),\n",
       "  array([-0.59860616,  0.00245609]),\n",
       "  array([-0.59459224,  0.00401391]),\n",
       "  array([-0.5910499 ,  0.00354235]),\n",
       "  array([-0.58800511,  0.00304479]),\n",
       "  array([-0.58548028,  0.00252483]),\n",
       "  array([-0.58249399,  0.00298628]),\n",
       "  array([-0.57906829,  0.0034257 ]),\n",
       "  array([-0.57622849,  0.00283981]),\n",
       "  array([-0.57399559,  0.00223289]),\n",
       "  array([-0.57138617,  0.00260943]),\n",
       "  array([-0.56841956,  0.00296661]),\n",
       "  array([-0.56611781,  0.00230175]),\n",
       "  array([-0.56249802,  0.00361978]),\n",
       "  array([-0.55958716,  0.00291086]),\n",
       "  array([-0.55540691,  0.00418025]),\n",
       "  array([-0.55198846,  0.00341845]),\n",
       "  array([-0.54735734,  0.00463112]),\n",
       "  array([-0.54354819,  0.00380915]),\n",
       "  array([-0.5385895 ,  0.00495869]),\n",
       "  array([-0.53251842,  0.00607108]),\n",
       "  array([-0.52638046,  0.00613797]),\n",
       "  array([-0.52122162,  0.00515883]),\n",
       "  array([-0.51608062,  0.005141  ]),\n",
       "  array([-0.511996  ,  0.00408462]),\n",
       "  array([-0.50899839,  0.00299762]),\n",
       "  array([-0.50711024,  0.00188815]),\n",
       "  array([-0.5063457 ,  0.00076454]),\n",
       "  array([-5.06710505e-01, -3.64804577e-04]),\n",
       "  array([-0.50820192, -0.00149141]),\n",
       "  array([-0.50980877, -0.00160685]),\n",
       "  array([-0.51251901, -0.00271024]),\n",
       "  array([-0.51431233, -0.00179333]),\n",
       "  array([-0.5161753 , -0.00186297]),\n",
       "  array([-0.51909394, -0.00291864]),\n",
       "  array([-0.52304636, -0.00395242]),\n",
       "  array([-0.52600293, -0.00295657]),\n",
       "  array([-0.52894146, -0.00293853]),\n",
       "  array([-0.53283993, -0.00389847]),\n",
       "  array([-0.53766909, -0.00482917]),\n",
       "  array([-0.54339276, -0.00572367]),\n",
       "  array([-0.54996807, -0.0065753 ]),\n",
       "  array([-0.5573458 , -0.00737774]),\n",
       "  array([-0.56347087, -0.00612507]),\n",
       "  array([-0.57029761, -0.00682674]),\n",
       "  array([-0.57577526, -0.00547764]),\n",
       "  array([-0.57986317, -0.00408792]),\n",
       "  array([-0.58453111, -0.00466793]),\n",
       "  array([-0.58974459, -0.00521348]),\n",
       "  array([-0.59546523, -0.00572064]),\n",
       "  array([-0.60165103, -0.00618581]),\n",
       "  array([-0.60825678, -0.00660575]),\n",
       "  array([-0.6132344 , -0.00497762]),\n",
       "  array([-0.61854782, -0.00531342]),\n",
       "  array([-0.62215872, -0.0036109 ]),\n",
       "  array([-0.62504114, -0.00288242]),\n",
       "  array([-0.62817443, -0.00313329]),\n",
       "  array([-0.63053621, -0.00236178]),\n",
       "  array([-0.63210965, -0.00157343]),\n",
       "  array([-0.63388355, -0.0017739 ]),\n",
       "  array([-0.63584532, -0.00196177]),\n",
       "  array([-0.63798106, -0.00213574]),\n",
       "  array([-0.63927568, -0.00129461]),\n",
       "  array([-6.38720021e-01,  5.55654269e-04]),\n",
       "  array([-6.38318019e-01,  4.02001665e-04]),\n",
       "  array([-0.63607251,  0.00224551]),\n",
       "  array([-0.63399936,  0.00207315]),\n",
       "  array([-0.63111326,  0.0028861 ]),\n",
       "  array([-0.62643471,  0.00467855]),\n",
       "  array([-0.62099707,  0.00543764]),\n",
       "  array([-0.6148393 ,  0.00615778]),\n",
       "  array([-0.60900573,  0.00583357]),\n",
       "  array([-0.60253859,  0.00646713]),\n",
       "  array([-0.59648493,  0.00605366]),\n",
       "  array([-0.58888896,  0.00759597]),\n",
       "  array([-0.58080645,  0.00808252]),\n",
       "  array([-0.57129698,  0.00950947]),\n",
       "  array([-0.56243099,  0.00886599]),\n",
       "  array([-0.55327442,  0.00915657]),\n",
       "  array([-0.54389557,  0.00937884]),\n",
       "  array([-0.53336459,  0.01053098]),\n",
       "  array([-0.52376038,  0.00960421]),\n",
       "  array([-0.51315496,  0.01060542]),\n",
       "  array([-0.50162786,  0.01152711]),\n",
       "  array([-0.49126541,  0.01036244]),\n",
       "  array([-0.48014509,  0.01112032]),\n",
       "  array([-0.47034975,  0.00979534]),\n",
       "  array([-0.46195208,  0.00839767]),\n",
       "  array([-0.45501412,  0.00693795]),\n",
       "  array([-0.44958693,  0.00542719]),\n",
       "  array([-0.44571028,  0.00387665]),\n",
       "  array([-0.4414125 ,  0.00429779]),\n",
       "  array([-0.43772488,  0.00368762]),\n",
       "  array([-0.43367421,  0.00405066]),\n",
       "  array([-0.43028983,  0.00338438]),\n",
       "  array([-0.42759617,  0.00269367]),\n",
       "  array([-0.42661261,  0.00098356]),\n",
       "  array([-0.42734622, -0.00073362]),\n",
       "  array([-0.42979174, -0.00244552]),\n",
       "  array([-0.43193157, -0.00213982]),\n",
       "  array([-0.43375026, -0.00181869]),\n",
       "  array([-0.43523469, -0.00148443]),\n",
       "  array([-0.43737411, -0.00213942]),\n",
       "  array([-0.43915303, -0.00177892]),\n",
       "  array([-0.44155854, -0.00240551]),\n",
       "  array([-0.44557316, -0.00401462]),\n",
       "  array([-0.44916764, -0.00359448]),\n",
       "  array([-0.45331573, -0.00414809])],\n",
       " [2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1],\n",
       " -200.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement generate_session_mountain_car(), training loop, etc.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * env.action_space.n, range(env.action_space.n), range(env.action_space.n))\n",
    "\n",
    "def generate_session_mountain_car(env, agent, t_max=10000):\n",
    "    \n",
    "    s = env.reset()\n",
    "    states,actions = [], []\n",
    "    reward = 0\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        probs = agent.predict_proba(s.reshape(1,-1)).flatten()\n",
    "        a = np.random.choice(np.arange(env.action_space.n), p =probs)\n",
    "        \n",
    "        new_s, r, done, _ = env.step(a)\n",
    "        \n",
    "        states.append(new_s)\n",
    "        actions.append(a)\n",
    "        reward += r\n",
    "        \n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    return states, actions, reward\n",
    "\n",
    "generate_session_mountain_car(env, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submit import submit_mountain_car\n",
    "submit_mountain_car(generate_session_mountain_car, agent, 'your.email@example.com', 'YourAssignmentToken')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
